* executing sh
```sh
docker exec -it countgdpp-server /bin/bash
```
``` sh
docker run -it countgdapp-server-gpu /bin/bash
```
This is a **very common Docker issue**, especially when running ML / inference workloads (model downloads, build caches, large layers). Docker is conservative about deleting things, so storage grows fast unless you clean it intentionally.

Below is a **safe ‚Üí aggressive cleanup ladder**, plus **ML-specific tips** for inference servers.

---

## 1Ô∏è‚É£ Check what‚Äôs actually using disk space (always do this first)

```bash
docker system df
```

Example output:

```
TYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLE
Images          28        4         120GB     95GB (79%)
Containers      14        2         4GB       3GB
Local Volumes   18        6         260GB     210GB
Build Cache     42                  30GB      30GB
```

‚ö†Ô∏è **Volumes are usually the real culprit**, not images.

---

## 2Ô∏è‚É£ Clean **stopped containers** (safe)

```bash
docker container prune
```

‚úî Removes containers not running
‚ùå Does NOT remove images or volumes

---

## 3Ô∏è‚É£ Remove **unused images** (safe)

```bash
docker image prune
```

To remove **all images not used by any container**:

```bash
docker image prune -a
```

‚ö†Ô∏è This will require re-pulling images later.

---

## 4Ô∏è‚É£ Clean **Docker build cache** (VERY important for ML)

Build cache grows fast when rebuilding inference servers.

```bash
docker builder prune
```

Or nuke all build cache:

```bash
docker builder prune --all
```

üí° This is usually **10‚Äì50GB reclaimed** on ML machines.

---

## 5Ô∏è‚É£ Remove **unused volumes** (biggest gain, but be careful)

```bash
docker volume prune
```

‚ö†Ô∏è This deletes volumes **not attached to running containers**
‚úî Safe if you don‚Äôt need old model data, logs, or DBs

To inspect volumes before deleting:

```bash
docker volume ls
docker volume inspect <volume_name>
```

---

## 6Ô∏è‚É£ One-command cleanup (recommended occasionally)

```bash
docker system prune
```

More aggressive:

```bash
docker system prune -a
```

**Max cleanup (images + volumes + cache):**

```bash
docker system prune -a --volumes
```

üö® **This deletes everything unused**
Only run this if you understand the consequences.

---

## 7Ô∏è‚É£ Find large files inside Docker storage (Linux)

Docker data lives here by default:

```bash
/var/lib/docker
```

Find large directories:

```bash
sudo du -h --max-depth=2 /var/lib/docker | sort -hr | head -20
```

Common space hogs:

* `overlay2/` ‚Üí image layers
* `volumes/` ‚Üí model files, caches
* `buildkit/` ‚Üí build cache

---

## 8Ô∏è‚É£ ML / inference-specific cleanup (VERY relevant for you)

### A. Model caches inside containers

Many frameworks cache models in:

* `/root/.cache`
* `/home/*/.cache`
* `/opt/models`
* `/app/models`

If these are inside a **volume**, they persist forever.

üëâ **Solution**
Mount model cache explicitly:

```bash
-v ~/model-cache:/models
```

Then clean manually:

```bash
rm -rf ~/model-cache/*
```

---

### B. HuggingFace / PyTorch cache

Common locations:

```bash
~/.cache/huggingface
~/.cache/torch
```

Clean safely:

```bash
rm -rf ~/.cache/huggingface/*
rm -rf ~/.cache/torch/*
```

Or limit cache size:

```bash
export HF_HOME=/models/hf
export TORCH_HOME=/models/torch
```

---

### C. Logs growing inside containers

Check logs:

```bash
docker ps -q | xargs -I {} docker logs --tail=10 {}
```

Docker log files live in:

```bash
/var/lib/docker/containers/*/*.log
```

Truncate logs safely:

```bash
sudo truncate -s 0 /var/lib/docker/containers/*/*.log
```

---

## 9Ô∏è‚É£ Prevent future disk explosions (strongly recommended)

### Limit log size

Create or edit:

```bash
/etc/docker/daemon.json
```

```json
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m",
    "max-file": "3"
  }
}
```

Restart Docker:

```bash
sudo systemctl restart docker
```

---

### Auto-clean build cache (CI style)

```bash
docker builder prune -af --filter until=24h
```

---

## 10Ô∏è‚É£ My recommended cleanup sequence for inference servers

Run this **monthly** (or when disk spikes):

```bash
docker container prune -f
docker image prune -af
docker builder prune -af
docker volume prune -f
```

Then:

```bash
docker system df
```

---

## üß† TL;DR (most effective commands)

```bash
docker system df
docker builder prune -af
docker volume prune
docker system prune -a --volumes
```

---
